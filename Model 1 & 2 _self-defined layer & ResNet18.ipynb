{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/242B_final_project') # customize this line to your working directory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62JgfpBBPAAm","executionInfo":{"status":"ok","timestamp":1714481068573,"user_tz":420,"elapsed":332730,"user":{"displayName":"YU TIAN","userId":"14313109169654091546"}},"outputId":"4d37f889-79a4-4746-e7b3-667d1b2c565f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/242B_final_project/np_save/\""],"metadata":{"id":"7i839wYOPZjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XPjtL4nydmMR"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from skimage.transform import resize\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from torch.nn import functional as F\n","from torchvision.models import resnet50\n","\n","import PIL.Image\n","from torchvision import transforms\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import random"]},{"cell_type":"code","source":["train_matched_pairs = np.load(f'{path}train_matched_pairs.npy', allow_pickle=True)\n","train_matched_labels = np.load(f'{path}train_matched_labels.npy', allow_pickle=True)\n","test_matched_pairs = np.load(f'{path}test_matched_pairs.npy', allow_pickle=True)\n","test_matched_labels = np.load(f'{path}test_matched_labels.npy', allow_pickle=True)\n","\n","train_mismatched_pairs = np.load(f'{path}train_mismatched_pairs.npy', allow_pickle=True)\n","train_mismatched_labels = np.load(f'{path}train_mismatched_labels.npy', allow_pickle=True)\n","test_mismatched_pairs = np.load(f'{path}test_mismatched_pairs.npy', allow_pickle=True)\n","test_mismatched_labels = np.load(f'{path}test_mismatched_labels.npy', allow_pickle=True)"],"metadata":{"id":"UXpQs4sQd0Py"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loader\n"],"metadata":{"id":"mT285oM7g9WJ"}},{"cell_type":"code","source":["class SiameseDataset(Dataset):\n","    def __init__(self, matched_pairs, matched_labels, mismatched_pairs, mismatched_labels):\n","        self.pairs = np.concatenate((matched_pairs, mismatched_pairs), axis=0)\n","        self.labels = np.concatenate((matched_labels, mismatched_labels), axis=0)\n","\n","        # Shuffle the data\n","        indices = np.arange(len(self.pairs))\n","        random.shuffle(indices)\n","        self.pairs = self.pairs[indices]\n","        self.labels = self.labels[indices]\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        img1 = self.pairs[idx][0]\n","        img2 = self.pairs[idx][1]\n","        label = self.labels[idx]\n","\n","        return img1, img2, label"],"metadata":{"id":"K_0HmcpyhFvl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = SiameseDataset(train_matched_pairs, train_matched_labels,\n","                                train_mismatched_pairs, train_mismatched_labels)\n","\n","test_dataset = SiameseDataset(test_matched_pairs, test_matched_labels,\n","                               test_mismatched_pairs, test_mismatched_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"],"metadata":{"id":"G9TIV7C6hLWU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model 1 - self defined (Siamese)"],"metadata":{"id":"DQF8C8MbOj93"}},{"cell_type":"code","source":["def calculate_accuracy(data_loader, model, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in data_loader:\n","            img1, img2, labels = data\n","            img1, img2 = img1.to(device), img2.to(device)\n","            labels = labels.to(device)\n","            labels = labels.squeeze()\n","            # print(f'labels: {labels}')\n","            outputs = model(img1, img2).squeeze()\n","            # print(f'Probability: {outputs}')\n","            predicted = (outputs > 0.5).float()  # Ensures it's a float tensor\n","            # print(f'Predicted: {predicted}')\n","            correct += (predicted == labels.float()).sum().item()  # Cast labels to float for comparison\n","            # print(f'Correct: {correct}')\n","            total += labels.size(0)\n","            # print(f'Total: {total}')\n","    return 100 * correct / total"],"metadata":{"id":"cf3zfYH6OrOr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","from torch.utils.data import DataLoader\n","\n","def train_model(model, criterion, num_epochs, optimizer, train_loader, test_loader): #test_loader\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.train()  # Set the model to training mode\n","\n","    # Logs for keeping track of loss and accuracy\n","    train_loss_log = []\n","    train_acc_log = []\n","    test_acc_log = []\n","\n","    tic = time.time()\n","\n","    for epoch in range(num_epochs):\n","        total_train_loss = 0\n","        model.train()  # Ensure model is in training mode\n","\n","        for data in train_loader:\n","            img1, img2, labels = data\n","            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(img1, img2)  # Adjusted to use the updated forward method\n","            loss = criterion(outputs, labels.float().view(-1, 1))\n","\n","            # Backward pass and optimize\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_train_loss += loss.item()\n","\n","        # Calculate average loss and accuracy for the epoch\n","        avg_train_loss = total_train_loss / len(train_loader)\n","        train_accuracy = calculate_accuracy(train_loader, model, device)\n","        test_accuracy = calculate_accuracy(test_loader, model, device)\n","\n","        train_loss_log.append(avg_train_loss)\n","        train_acc_log.append(train_accuracy)\n","        test_acc_log.append(test_accuracy)\n","\n","        # Print statistics\n","        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')\n","        # print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n","\n","    toc = time.time()\n","    print(\"Elapsed Time : {:7.2f}\".format(toc-tic))\n","\n","    return train_loss_log, train_acc_log , test_acc_log\n"],"metadata":{"id":"S1HGvGkUOzAK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# self define the model\n","class SiameseNetwork(nn.Module):\n","    def __init__(self):\n","        super(SiameseNetwork, self).__init__()\n","\n","        # Convolutional layers\n","        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)  # Input is 224x224x3, output is 224x224x16\n","        self.conv2 = nn.Conv2d(16, 32, 3, padding=1) # Input is 112x112x16, output is 112x112x32\n","        self.conv3 = nn.Conv2d(32, 64, 3, padding=1) # Input is 56x56x32, output is 56x56x64\n","\n","        # Pooling layer\n","        self.pool = nn.MaxPool2d(2, 2)\n","\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(64 * 28 * 28, 500)\n","        self.fc2 = nn.Linear(500, 256)\n","        self.fc3 = nn.Linear(256, 128)\n","\n","        # Classification layer\n","        self.classifier = nn.Linear(128, 1)  # Outputs probability of match\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward_once(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        return x\n","\n","    def forward(self, input1, input2):\n","        output1 = self.forward_once(input1)\n","        output2 = self.forward_once(input2)\n","\n","        # Calculate the absolute difference between the outputs\n","        difference = torch.abs(output1 - output2)\n","        logits = self.classifier(difference)\n","        probability = self.sigmoid(logits)\n","        return probability"],"metadata":{"id":"HLOuqaVUOsL_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = SiameseNetwork()\n","num_epochs = 10\n","criterion = nn.BCELoss()  # Ensure the label and output size match\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","train_loss_log, train_acc_log, test_acc_log= train_model(model, criterion, num_epochs, optimizer, train_loader, test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vkR1l5owO2Jc","executionInfo":{"status":"ok","timestamp":1714484169705,"user_tz":420,"elapsed":3036931,"user":{"displayName":"YU TIAN","userId":"14313109169654091546"}},"outputId":"643abf35-e731-4f3c-9eff-c2c329264642"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Training Loss: 0.6939, Training Accuracy: 53.36%, Test Accuracy: 49.90%\n","Epoch 2/10, Training Loss: 0.6695, Training Accuracy: 56.73%, Test Accuracy: 54.40%\n","Epoch 3/10, Training Loss: 0.6488, Training Accuracy: 61.86%, Test Accuracy: 57.20%\n","Epoch 4/10, Training Loss: 0.6117, Training Accuracy: 71.82%, Test Accuracy: 62.30%\n","Epoch 5/10, Training Loss: 0.5647, Training Accuracy: 78.41%, Test Accuracy: 61.10%\n","Epoch 6/10, Training Loss: 0.5063, Training Accuracy: 82.32%, Test Accuracy: 61.20%\n","Epoch 7/10, Training Loss: 0.4071, Training Accuracy: 87.18%, Test Accuracy: 60.20%\n","Epoch 8/10, Training Loss: 0.3031, Training Accuracy: 93.14%, Test Accuracy: 60.40%\n","Epoch 9/10, Training Loss: 0.2037, Training Accuracy: 95.77%, Test Accuracy: 61.00%\n","Epoch 10/10, Training Loss: 0.1375, Training Accuracy: 96.64%, Test Accuracy: 62.30%\n","Elapsed Time : 3035.92\n"]}]},{"cell_type":"markdown","source":["# Model 2 - ResNet18"],"metadata":{"id":"seavUHZUoqOq"}},{"cell_type":"code","source":["class ResNetModel(nn.Module):\n","    def __init__(self):\n","        super(ResNetModel, self).__init__()\n","        # Load a pre-trained ResNet and remove the last fully connected layer\n","        base_model = models.resnet18(pretrained=True)\n","        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-1])\n","\n","        # Classification layer\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512, 1),  # Adjust the input features to match the output of your feature extractor\n","            nn.Sigmoid()\n","        )\n","\n","    def forward_once(self, x):\n","        x = self.feature_extractor(x)\n","        x = torch.flatten(x, 1)  # Flatten the features\n","        return x\n","\n","    def forward(self, input1, input2):\n","        output1 = self.forward_once(input1)\n","        output2 = self.forward_once(input2)\n","\n","        # Calculate the absolute difference between the outputs\n","        difference = torch.abs(output1 - output2)\n","        probability = self.classifier(difference)\n","\n","        return probability"],"metadata":{"id":"ZqnvBdNg0pyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = ResNetModel()\n","num_epochs = 10\n","criterion = nn.BCELoss()  # Ensure the label and output size match\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","train_loss_log, train_acc_log, test_acc_log= train_model(model, criterion, num_epochs, optimizer, train_loader, test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3o_Jxn5J0_9j","executionInfo":{"status":"ok","timestamp":1714499687533,"user_tz":420,"elapsed":5303242,"user":{"displayName":"YU TIAN","userId":"14313109169654091546"}},"outputId":"b09eb220-c9c8-4628-c3ae-bdb0a291b638"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 102MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Training Loss: 0.6762, Training Accuracy: 65.59%, Test Accuracy: 60.40%\n","Epoch 2/10, Training Loss: 0.6195, Training Accuracy: 56.05%, Test Accuracy: 54.80%\n","Epoch 3/10, Training Loss: 0.5981, Training Accuracy: 71.41%, Test Accuracy: 62.90%\n","Epoch 4/10, Training Loss: 0.5468, Training Accuracy: 74.64%, Test Accuracy: 65.40%\n","Epoch 5/10, Training Loss: 0.4999, Training Accuracy: 74.05%, Test Accuracy: 66.00%\n","Epoch 6/10, Training Loss: 0.4775, Training Accuracy: 83.36%, Test Accuracy: 67.10%\n","Epoch 7/10, Training Loss: 0.4196, Training Accuracy: 83.14%, Test Accuracy: 66.70%\n","Epoch 8/10, Training Loss: 0.3420, Training Accuracy: 87.95%, Test Accuracy: 70.10%\n","Epoch 9/10, Training Loss: 0.2912, Training Accuracy: 90.68%, Test Accuracy: 65.00%\n","Epoch 10/10, Training Loss: 0.2340, Training Accuracy: 92.55%, Test Accuracy: 69.80%\n","Elapsed Time : 15517.45\n"]}]}]}