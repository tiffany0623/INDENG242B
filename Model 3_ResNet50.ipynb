{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3857,"status":"ok","timestamp":1714480945631,"user":{"displayName":"YU TIAN","userId":"14313109169654091546"},"user_tz":420},"id":"62JgfpBBPAAm","outputId":"55705550-3784-468a-ed57-1b9245e933fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/242B_final_project') # customize this line to your working directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7i839wYOPZjy"},"outputs":[],"source":["path = \"/content/drive/MyDrive/242B_final_project/np_save/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XPjtL4nydmMR"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from skimage.transform import resize\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from torch.nn import functional as F\n","from torchvision.models import resnet50\n","\n","import PIL.Image\n","from torchvision import transforms\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXpQs4sQd0Py"},"outputs":[],"source":["train_matched_pairs = np.load(f'{path}train_matched_pairs.npy', allow_pickle=True)\n","train_matched_labels = np.load(f'{path}train_matched_labels.npy', allow_pickle=True)\n","test_matched_pairs = np.load(f'{path}test_matched_pairs.npy', allow_pickle=True)\n","test_matched_labels = np.load(f'{path}test_matched_labels.npy', allow_pickle=True)\n","\n","train_mismatched_pairs = np.load(f'{path}train_mismatched_pairs.npy', allow_pickle=True)\n","train_mismatched_labels = np.load(f'{path}train_mismatched_labels.npy', allow_pickle=True)\n","test_mismatched_pairs = np.load(f'{path}test_mismatched_pairs.npy', allow_pickle=True)\n","test_mismatched_labels = np.load(f'{path}test_mismatched_labels.npy', allow_pickle=True)"]},{"cell_type":"markdown","metadata":{"id":"mT285oM7g9WJ"},"source":["# Data Loader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_0HmcpyhFvl"},"outputs":[],"source":["class SiameseDataset(Dataset):\n","    def __init__(self, matched_pairs, matched_labels, mismatched_pairs, mismatched_labels):\n","        self.pairs = np.concatenate((matched_pairs, mismatched_pairs), axis=0)\n","        self.labels = np.concatenate((matched_labels, mismatched_labels), axis=0)\n","\n","        # Shuffle the data\n","        indices = np.arange(len(self.pairs))\n","        random.shuffle(indices)\n","        self.pairs = self.pairs[indices]\n","        self.labels = self.labels[indices]\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        img1 = self.pairs[idx][0]\n","        img2 = self.pairs[idx][1]\n","        label = self.labels[idx]\n","\n","        return img1, img2, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9TIV7C6hLWU"},"outputs":[],"source":["train_dataset = SiameseDataset(train_matched_pairs, train_matched_labels,\n","                                train_mismatched_pairs, train_mismatched_labels)\n","\n","test_dataset = SiameseDataset(test_matched_pairs, test_matched_labels,\n","                               test_mismatched_pairs, test_mismatched_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"DQF8C8MbOj93"},"source":["# Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cf3zfYH6OrOr"},"outputs":[],"source":["def calculate_accuracy(data_loader, model, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in data_loader:\n","            img1, img2, labels = data\n","            img1, img2 = img1.to(device), img2.to(device)\n","            labels = labels.to(device)\n","            labels = labels.squeeze()\n","            # print(f'labels: {labels}')\n","            outputs = model(img1, img2).squeeze()\n","            # print(f'Probability: {outputs}')\n","            predicted = (outputs > 0.5).float()  # Ensures it's a float tensor\n","            # print(f'Predicted: {predicted}')\n","            correct += (predicted == labels.float()).sum().item()  # Cast labels to float for comparison\n","            # print(f'Correct: {correct}')\n","            total += labels.size(0)\n","            # print(f'Total: {total}')\n","    return 100 * correct / total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S1HGvGkUOzAK"},"outputs":[],"source":["import time\n","from torch.utils.data import DataLoader\n","\n","def train_model(model, criterion, num_epochs, optimizer, train_loader, test_loader): #test_loader\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.train()  # Set the model to training mode\n","\n","    # Logs for keeping track of loss and accuracy\n","    train_loss_log = []\n","    train_acc_log = []\n","    test_acc_log = []\n","\n","    tic = time.time()\n","\n","    for epoch in range(num_epochs):\n","        total_train_loss = 0\n","        model.train()  # Ensure model is in training mode\n","\n","        for data in train_loader:\n","            img1, img2, labels = data\n","            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(img1, img2)  # Adjusted to use the updated forward method\n","            loss = criterion(outputs, labels.float().view(-1, 1))\n","\n","            # Backward pass and optimize\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_train_loss += loss.item()\n","\n","        # Calculate average loss and accuracy for the epoch\n","        avg_train_loss = total_train_loss / len(train_loader)\n","        train_accuracy = calculate_accuracy(train_loader, model, device)\n","        test_accuracy = calculate_accuracy(test_loader, model, device)\n","\n","        train_loss_log.append(avg_train_loss)\n","        train_acc_log.append(train_accuracy)\n","        test_acc_log.append(test_accuracy)\n","\n","        # Print statistics\n","        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')\n","        #print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n","\n","    toc = time.time()\n","    print(\"Elapsed Time : {:7.2f}\".format(toc-tic))\n","\n","    return train_loss_log, train_acc_log , test_acc_log\n"]},{"cell_type":"markdown","metadata":{"id":"seavUHZUoqOq"},"source":["# Model 3 - ResNet50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZqnvBdNg0pyr"},"outputs":[],"source":["class ResNet50Model(nn.Module):\n","    def __init__(self):\n","        super(ResNet50Model, self).__init__()\n","        base_model = models.resnet50(pretrained=True)\n","\n","        # Freeze all the layers\n","        for param in base_model.parameters():\n","            param.requires_grad = False\n","\n","        # Remove the final fully connected layer and modify the architecture\n","        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-1])\n","        self.reduction = nn.Sequential(\n","            nn.Conv2d(2048, 128, 1),  # Reducing the channels from 2048 to 128\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d((1, 1))  # Global Average Pooling\n","        )\n","\n","        # Classification layer\n","        self.classifier = nn.Sequential(\n","            nn.Linear(128, 1),  # Adjust the number of input features\n","            nn.Sigmoid()\n","        )\n","\n","    def forward_once(self, x):\n","        x = self.feature_extractor(x)\n","        x = self.reduction(x)\n","        x = torch.flatten(x, 1)  # Flatten the features\n","        return x\n","\n","    def forward(self, input1, input2):\n","        output1 = self.forward_once(input1)\n","        output2 = self.forward_once(input2)\n","\n","        # Calculate the absolute difference between the outputs\n","        difference = torch.abs(output1 - output2)\n","        probability = self.classifier(difference)\n","\n","        return probability"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkEfA1H-KjAe","outputId":"f73fb31e-378e-43d1-b2a9-d8015e974915"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Training Loss: 0.6497, Training Accuracy: 82.09%, Test Accuracy: 68.80%\n","Epoch 2/10, Training Loss: 0.5084, Training Accuracy: 91.91%, Test Accuracy: 67.60%\n","Epoch 3/10, Training Loss: 0.3715, Training Accuracy: 96.68%, Test Accuracy: 69.10%\n","Epoch 4/10, Training Loss: 0.2501, Training Accuracy: 99.00%, Test Accuracy: 68.80%\n","Epoch 5/10, Training Loss: 0.1552, Training Accuracy: 99.68%, Test Accuracy: 68.80%\n","Epoch 6/10, Training Loss: 0.1132, Training Accuracy: 99.86%, Test Accuracy: 67.80%\n","Epoch 7/10, Training Loss: 0.0780, Training Accuracy: 100.00%, Test Accuracy: 68.10%\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = ResNet50Model().to(device)\n","num_epochs = 10\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n","\n","# Assuming 'train_model' function is defined and 'train_loader' is available\n","train_loss_log, train_acc_log, test_acc_log = train_model(model, criterion, num_epochs, optimizer, train_loader, test_loader)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}