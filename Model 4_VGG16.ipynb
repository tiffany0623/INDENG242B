{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/242B_final_project') # customize this line to your working directory"],"metadata":{"id":"62JgfpBBPAAm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714482605840,"user_tz":420,"elapsed":2181,"user":{"displayName":"YU TIAN","userId":"14313109169654091546"}},"outputId":"d5678107-a98c-406d-aa7a-6ca6ecd15c92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/242B_final_project/np_save/\""],"metadata":{"id":"7i839wYOPZjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XPjtL4nydmMR"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from skimage.transform import resize\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from torch.nn import functional as F\n","from torchvision.models import resnet50\n","\n","import PIL.Image\n","from torchvision import transforms\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.cuda.amp import GradScaler, autocast\n","import random"]},{"cell_type":"code","source":["train_matched_pairs = np.load(f'{path}train_matched_pairs.npy', allow_pickle=True)\n","train_matched_labels = np.load(f'{path}train_matched_labels.npy', allow_pickle=True)\n","test_matched_pairs = np.load(f'{path}test_matched_pairs.npy', allow_pickle=True)\n","test_matched_labels = np.load(f'{path}test_matched_labels.npy', allow_pickle=True)\n","\n","train_mismatched_pairs = np.load(f'{path}train_mismatched_pairs.npy', allow_pickle=True)\n","train_mismatched_labels = np.load(f'{path}train_mismatched_labels.npy', allow_pickle=True)\n","test_mismatched_pairs = np.load(f'{path}test_mismatched_pairs.npy', allow_pickle=True)\n","test_mismatched_labels = np.load(f'{path}test_mismatched_labels.npy', allow_pickle=True)"],"metadata":{"id":"UXpQs4sQd0Py"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loader\n"],"metadata":{"id":"mT285oM7g9WJ"}},{"cell_type":"code","source":["class SiameseDataset(Dataset):\n","    def __init__(self, matched_pairs, matched_labels, mismatched_pairs, mismatched_labels):\n","        self.pairs = np.concatenate((matched_pairs, mismatched_pairs), axis=0)\n","        self.labels = np.concatenate((matched_labels, mismatched_labels), axis=0)\n","\n","        # Shuffle the data\n","        indices = np.arange(len(self.pairs))\n","        random.shuffle(indices)\n","        self.pairs = self.pairs[indices]\n","        self.labels = self.labels[indices]\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        img1 = self.pairs[idx][0]\n","        img2 = self.pairs[idx][1]\n","        label = self.labels[idx]\n","\n","        return img1, img2, label"],"metadata":{"id":"K_0HmcpyhFvl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = SiameseDataset(train_matched_pairs, train_matched_labels,\n","                                train_mismatched_pairs, train_mismatched_labels)\n","\n","test_dataset = SiameseDataset(test_matched_pairs, test_matched_labels,\n","                               test_mismatched_pairs, test_mismatched_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"],"metadata":{"id":"G9TIV7C6hLWU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Function"],"metadata":{"id":"DQF8C8MbOj93"}},{"cell_type":"code","source":["def calculate_accuracy(data_loader, model, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in data_loader:\n","            img1, img2, labels = data\n","            img1, img2 = img1.to(device), img2.to(device)\n","            labels = labels.to(device)\n","            labels = labels.squeeze()\n","            # print(f'labels: {labels}')\n","            outputs = model(img1, img2).squeeze()\n","            # print(f'Probability: {outputs}')\n","            predicted = (outputs > 0.5).float()  # Ensures it's a float tensor\n","            # print(f'Predicted: {predicted}')\n","            correct += (predicted == labels.float()).sum().item()  # Cast labels to float for comparison\n","            # print(f'Correct: {correct}')\n","            total += labels.size(0)\n","            # print(f'Total: {total}')\n","    return 100 * correct / total"],"metadata":{"id":"cf3zfYH6OrOr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","from torch.utils.data import DataLoader\n","\n","def train_model(model, criterion, num_epochs, optimizer, train_loader, test_loader): #test_loader\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.train()  # Set the model to training mode\n","\n","    # Logs for keeping track of loss and accuracy\n","    train_loss_log = []\n","    train_acc_log = []\n","    test_acc_log = []\n","\n","    tic = time.time()\n","\n","    for epoch in range(num_epochs):\n","        total_train_loss = 0\n","        model.train()  # Ensure model is in training mode\n","\n","        for data in train_loader:\n","            img1, img2, labels = data\n","            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(img1, img2)  # Adjusted to use the updated forward method\n","            loss = criterion(outputs, labels.float().view(-1, 1))\n","\n","            # Backward pass and optimize\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_train_loss += loss.item()\n","\n","        # Calculate average loss and accuracy for the epoch\n","        avg_train_loss = total_train_loss / len(train_loader)\n","        train_accuracy = calculate_accuracy(train_loader, model, device)\n","        test_accuracy = calculate_accuracy(test_loader, model, device)\n","\n","        train_loss_log.append(avg_train_loss)\n","        train_acc_log.append(train_accuracy)\n","        test_acc_log.append(test_accuracy)\n","\n","        # Print statistics\n","        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')\n","        # print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n","\n","    toc = time.time()\n","    print(\"Elapsed Time : {:7.2f}\".format(toc-tic))\n","\n","    return train_loss_log, train_acc_log , test_acc_log\n"],"metadata":{"id":"S1HGvGkUOzAK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model 4 - VGG16"],"metadata":{"id":"seavUHZUoqOq"}},{"cell_type":"code","source":["class SiameseVGG16(nn.Module):\n","    def __init__(self):\n","        super(SiameseVGG16, self).__init__()\n","        # Load a pre-trained VGG16 model\n","        self.vgg16 = models.vgg16(pretrained=True)\n","\n","        # Remove the classifier part and retain only the features\n","        self.features = self.vgg16.features\n","\n","        # Freeze the feature extraction part to not train it again\n","        for param in self.features.parameters():\n","            param.requires_grad = False\n","\n","        # Adding an adaptive pooling layer before the classifier\n","        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))  # Outputs a fixed size regardless of input size\n","\n","        # Adding a new classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 7 * 7, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(256, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward_once(self, x):\n","        # Forward pass through VGG16 features\n","        x = self.features(x)\n","        x = self.adaptive_pool(x)\n","        x = torch.flatten(x, 1)  # Flatten the features\n","        return x\n","\n","    def forward(self, input1, input2):\n","        # Generate features from both inputs\n","        output1 = self.forward_once(input1)\n","        output2 = self.forward_once(input2)\n","\n","        # Concatenate or subtract features (depending on your approach)\n","        combined_features = torch.abs(output1 - output2)\n","\n","        # Pass through the classifier to get the final output\n","        similarity = self.classifier(combined_features)\n","        return similarity\n","\n","# Example of initializing the model\n","model = SiameseVGG16()"],"metadata":{"id":"drHEc_KkqNw-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714482642379,"user_tz":420,"elapsed":6974,"user":{"displayName":"YU TIAN","userId":"14313109169654091546"}},"outputId":"f19b3fb7-0b03-4b61-d7a2-16db4d568ac5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_epochs = 10\n","criterion = nn.BCELoss()  # Ensure the label and output size match\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","train_loss_log, train_acc_log, test_acc_log= train_model(model, criterion, num_epochs, optimizer, train_loader, test_loader)"],"metadata":{"id":"osEy1IeJSR2M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714483164248,"user_tz":420,"elapsed":521873,"user":{"displayName":"YU TIAN","userId":"14313109169654091546"}},"outputId":"dfb830f7-6345-45fa-8d5c-c58c3105ec08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Training Loss: 1.0462, Training Accuracy: 75.55%, Test Accuracy: 58.50%\n","Epoch 2/10, Training Loss: 0.5659, Training Accuracy: 88.59%, Test Accuracy: 62.90%\n","Epoch 3/10, Training Loss: 0.4156, Training Accuracy: 94.73%, Test Accuracy: 69.40%\n","Epoch 4/10, Training Loss: 0.3019, Training Accuracy: 97.45%, Test Accuracy: 68.50%\n","Epoch 5/10, Training Loss: 0.2302, Training Accuracy: 98.05%, Test Accuracy: 65.10%\n","Epoch 6/10, Training Loss: 0.1674, Training Accuracy: 99.14%, Test Accuracy: 68.80%\n","Epoch 7/10, Training Loss: 0.1229, Training Accuracy: 99.55%, Test Accuracy: 69.00%\n","Epoch 8/10, Training Loss: 0.1359, Training Accuracy: 98.91%, Test Accuracy: 66.20%\n","Epoch 9/10, Training Loss: 0.0924, Training Accuracy: 99.64%, Test Accuracy: 68.20%\n","Epoch 10/10, Training Loss: 0.0861, Training Accuracy: 99.77%, Test Accuracy: 67.80%\n","Elapsed Time :  524.31\n"]}]}]}